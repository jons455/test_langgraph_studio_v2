from langchain_core.messages import SystemMessage, AIMessage, HumanMessage
from imc_agents.costum_llm_model import CustomChatModel
from langgraph.graph import StateGraph
from imc_agents.agents.onboarding_agent import create_onboarding_graph
from imc_agents.agents.data_validation_agent import create_validation_graph
from imc_agents.agents.state import State

llm = CustomChatModel(model="GPT-4o")

def supervisor_router(state: State) -> str:
    # Nur beim ersten Mal prÃ¼fen (Mock)
    if state.get("restored_from_db", False):
        print("ğŸ” Lade Konversation aus der DB... (mocked)")
        state["restored_from_db"] = True


    if not state.get("has_greeted"):
        greeting = AIMessage(content="Hallo, ich freue mich, Sie zu unterstÃ¼tzen! Was kann ich fÃ¼r Sie tun?")
        state["messages"] = [greeting] + state["messages"]
        state["has_greeted"] = True

    instruction = SystemMessage(content=("""
Du bist der zentrale Router fÃ¼r ein Siemens Agentensystem und leitest Anfragen von Distributoren an spezialisierte Agenten weiter.
Deine Kommunikation ist stets professionell, prÃ¤zise und auf den Punkt gebracht.

**AgentenÃ¼bersicht:**
- **Onboarding-Agent**: Dein Experte fÃ¼r alle anfÃ¤nglichen Anfragen. WÃ¤hle diesen Agenten fÃ¼r Themen wie Ersteinrichtung, EDI-Anbindung, mÃ¶gliche Ãœbertragungswege (API, IDoc, CSV), Stammdaten und allgemeine technische Erstberatung.
    - Beispiele: â€Wie kann ich meine Daten hochladen?â€œ, â€ErklÃ¤ren Sie mir die Anbindung via EDI.â€œ, â€Welche Schnittstellen gibt es?â€œ

- **Validierungs-Agent**: Dein Spezialist fÃ¼r die DatenprÃ¼fung. WÃ¤hle diesen Agenten, wenn es um die ÃœberprÃ¼fung von Dateien, Formaten, Pflichtfeldern oder die Analyse von Fehlern bei abgelehnten Uploads geht.
    - Beispiele: â€PrÃ¼fen Sie bitte meine Datei.â€œ, â€Sind alle Pflichtfelder in meinem Dokument korrekt?â€œ, â€Warum wurde mein Upload abgelehnt?â€œ

**Deine Aufgabe:**
Analysiere die letzte Nutzernachricht und wÃ¤hle den passenden Agenten. Wenn Du unsicher bist, bevorzuge 'validation' bei konkreten Datenfragen und 'onboarding' bei allgemeinen, konzeptionellen Anfragen.

**Antwortvorgabe:** Gib **ausschlieÃŸlich** eines der folgenden SchlÃ¼sselwÃ¶rter zurÃ¼ck, ohne jegliche ZusÃ¤tze:
- `onboarding`
- `validation`
- `smalltalk`
"""
                                ))
    task_type = state.get("task_type")
    if task_type in {"onboarding", "validation", "smalltalk", "fallback"}:
        # Entscheidung wurde bereits getroffen â†’ wiederverwenden
        print(state["task_type"])
        return state["task_type"]

    # Entscheidung noch nicht getroffen â†’ LLM-Call durchfÃ¼hren
    messages = [instruction] + state["messages"]
    decision = llm.invoke(messages).content.strip().lower()
    print(decision)

    if decision in {"onboarding", "validation", "smalltalk"}:
        state["task_type"] = decision
        return decision

    state["task_type"] = "fallback"
    return "fallback"


def smalltalk(state: State):
    user_input = state["messages"][-1].content if state["messages"] else ""

    messages = [
        SystemMessage(content=("""
Du bist ein professioneller und sympathischer Berater bei Siemens.
Wenn die Anfrage des Nutzers informell ist (z.B. eine BegrÃ¼ÃŸung oder eine allgemeine Frage), reagiere freundlich und professionell.

**Wichtige Regeln:**
- Antworte kurz und hÃ¶flich.
- ErzÃ¤hle **nur dann einen Witz**, wenn der Nutzer **explizit** danach fragt.
- Leite das GesprÃ¤ch proaktiv wieder auf die Kernthemen, indem du fragst, ob der Nutzer Hilfe bei der Systemanbindung (Onboarding) oder der DatenprÃ¼fung (Validierung) benÃ¶tigt.
- Vermeide Umgangssprache und bleibe stets im Rahmen einer professionellen Siemens-Kommunikation.

**Beispiele:**
- Nutzer: â€Wie geht's?â€œ â†’ Antworte kurz und professionell und frage dann, wie du helfen kannst (Onboarding oder Validierung).
- Nutzer: â€Was machst du so?â€œ â†’ ErklÃ¤re kurz, dass du bei der Anbindung und DatenprÃ¼fung fÃ¼r Siemens-Partner hilfst.
"""
            )),
        HumanMessage(content=user_input)
    ]

    response = llm.invoke(messages)

    return {
        "messages": state["messages"] + [response]
    }


def build_supervisor_graph():
    graph = StateGraph(State)

    graph.add_node("Supervisor Agent", lambda s: {"messages": s["messages"]})
    graph.add_conditional_edges(
    "Supervisor Agent",
    supervisor_router,  # deine Routing-Logik
    {
        "onboarding": "Onboarding Agent",
        "validation": "Validation Agent",
        #"smalltalk": "smalltalk",
        #"fallback": "fallback",
    }
)

    graph.add_node("Onboarding Agent", create_onboarding_graph())
    graph.add_node("Validation Agent", create_validation_graph())

    # Mocked Smalltalk-Handler
    #graph.add_node("smalltalk", smalltalk)

    # Fallback, falls nichts zugeordnet werden kann
   # graph.add_node("fallback", lambda s: {
    #    "messages": s["messages"] + [AIMessage(content="Ich konnte das Anliegen leider nicht zuordnen.")]
    #})

    graph.add_edge("Onboarding Agent", "__end__")
    graph.add_edge("Validation Agent", "__end__")
   
   # graph.add_edge("smalltalk", "__end__")
   # graph.add_edge("fallback", "__end__")

    graph.set_entry_point("Supervisor Agent")
    return graph.compile()

